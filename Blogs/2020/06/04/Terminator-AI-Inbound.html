<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width", initial-scale="1.0">
        <link rel="stylesheet" href="../../../../css/menu.css"/>
        <link rel="icon" href="../../../../AboutMe/Images/1280px-Flag_of_Johannesburg,_South_Africa.svg.png">
        <title> Jozi Life </title>
        <script src="../../../../index.js"></script>
    </head>
    <body>
        <header align = "center">
            <section id = "navigation_bar"> </section>

            <script src="../../../../JavaScript/menu.js"></script>
            <!-- <nav> <a href="../../../../index.html"> <img src="../../../../AboutMe/Images/1280px-Flag_of_Johannesburg,_South_Africa.svg.png" alt="Flag of Johannesburg" width="200px" height=100px> Jozi Life</a></nav>

            <a href="../../../../index.html"> Home </a>
            &nbsp;

            <a href="../../../../AboutMe/AboutMe.html"> About Me </a>
            &nbsp;

            <a href="../../../../Blogs/DainBlog.html"> Dain's Entries </a>
            &nbsp;

            <a href="../../../../JoziBlogs/JoziBlog.html"> Jozi's Entries </a>

            <br>
            <br> -->

            <button onclick="backbutton()"> Back </button>
        </header>

        <section>
            <article>
                <h1>
                    Terminator AI Inbound?
                </h1>

                <p>
                    @Phxtho (twitter) - “Fama.io is further proof that AI doesn’t have to be smart to be dangerous. Bad assumptions at scale”.
                </p>

                <p>
                    Fama uses AI to screen for what that describe as “undesirable” behaviours. Many companies and institutions have taken on this technology and are using it during their interviewing and screen processes. But the AI is notoriously inexplicable and prone to bias so it is very likely it would entrench existing biases (sexism, racism etc).
                </p>

                <p>
                    I recently saw a tweet about a guy who had a background check for a job by the Fama AI system and it turned out a 300+ page report of every single tweet the guy had ever like with the word “fuck” in it. This is leading me to believe that this tech is just a word search. Our worst dystopian nightmares are coming true. In another instance a professor who was screened was flagged for having talked about religion on twitter. This is scary because A) now we can’t tweet what we want to anymore and B) it actually turned out the man was a professor in religious history. 
                </p>

                <p>
                    It’s clear that the system is not super intelligent and that the system designers clearly made some assumptions and guesses as to what is “good” and “bad” and now that automated way of thinking is out there deciding whether or not people get employed. Talk about an algorithm of oppression.
                </p>

                <p>
                    I think the tweet is attacking the assumption people have that killer ai is some terminator-like, advanced system that is super intelligent and becomes hellbent on destroying the world when in fact the future could just be our dumb, poorly designed AI systems being allowed to determine how we live our lives. 
                </p>
            </article>
        </section>
        <footer>
            Background Image Credits: https://www.once.travel/tour/graffiti-tour-braamfontein/
        </footer>
    </body>
</html>